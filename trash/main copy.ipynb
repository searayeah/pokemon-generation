{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# !unzip /content/drive/MyDrive/colab/images.zip\n",
    "# !pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchaudio\n",
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as utils\n",
    "import tqdm\n",
    "from IPython import display\n",
    "from IPython.display import HTML, clear_output\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import resnet18\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    # torch.backends.cudnn.deterministic = True\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mseara\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# warnings.filterwarnings(\"ignore\")\n",
    "set_seed(3407)\n",
    "wandb.login()\n",
    "\n",
    "# model.zero_grad()\n",
    "# loss.backward()\n",
    "# optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DATAROOT = (\n",
    "    \"/home/seara/Desktop/Github/vk-try/images\"\n",
    "    if os.path.isdir(\"/home/seara/Desktop/Github/vk-try/images\")\n",
    "    else \"/content/images\"\n",
    ")\n",
    "WORKERS = 4\n",
    "BATCH_SIZE = 512\n",
    "NUM_EPOCHS = 2000\n",
    "LR = 0.0002\n",
    "BETA1 = 0.5\n",
    "IMAGE_SIZE = (64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=100,\n",
    "                out_channels=1024,\n",
    "                kernel_size=4,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=1024,\n",
    "                out_channels=512,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=512,\n",
    "                out_channels=256,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=256,\n",
    "                out_channels=128,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        self.output = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=128,\n",
    "                out_channels=3,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=True,\n",
    "            ),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.main(x)\n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=3,\n",
    "                out_channels=64,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=128,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_channels=128,\n",
    "                out_channels=256,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_channels=256,\n",
    "                out_channels=512,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=512,\n",
    "                out_channels=1,\n",
    "                kernel_size=4,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.main(x)\n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN:\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_epochs,\n",
    "        lr,\n",
    "        beta1,\n",
    "        device,\n",
    "    ):\n",
    "\n",
    "        self.num_epochs = num_epochs\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.device = device\n",
    "\n",
    "        self.real_label = 1.0\n",
    "        self.fake_label = 0.0\n",
    "\n",
    "        self.G = Generator()\n",
    "        self.D = Discriminator()\n",
    "\n",
    "        self.G.apply(weights_init)\n",
    "        self.D.apply(weights_init)\n",
    "\n",
    "        self.G.to(self.device)\n",
    "        self.D.to(self.device)\n",
    "\n",
    "        self.loss = nn.BCELoss()\n",
    "\n",
    "        self.d_optimizer = optim.Adam(\n",
    "            self.D.parameters(), lr=self.lr, betas=(self.beta1, 0.999)\n",
    "        )\n",
    "        self.g_optimizer = optim.Adam(\n",
    "            self.G.parameters(), lr=self.lr, betas=(self.beta1, 0.999)\n",
    "        )\n",
    "        print(self.G)\n",
    "        print(self.D)\n",
    "\n",
    "    def train(self, dataloader):\n",
    "        wandb.init(project=\"vk_try\", name=\"leaky relu\")\n",
    "        # wandb.watch(model)\n",
    "\n",
    "        self.G.train()\n",
    "        self.D.train()\n",
    "\n",
    "        losses = []\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "            d_loss_list = []\n",
    "            d_loss_real_list = []\n",
    "            d_loss_fake_list = []\n",
    "            g_loss_list = []\n",
    "            for i, (real_images, _) in enumerate(dataloader):\n",
    "                # Discriminator step\n",
    "                self.D.zero_grad()\n",
    "\n",
    "                real_images = real_images.to(self.device)\n",
    "                current_batch_size = real_images.size(0)\n",
    "\n",
    "                label = torch.ones(current_batch_size, device=self.device)\n",
    "                d_real_output = self.D(real_images).flatten()\n",
    "                d_loss_real = self.loss(d_real_output, label)\n",
    "\n",
    "                noise = torch.randn(current_batch_size, 100, 1, 1, device=self.device)\n",
    "\n",
    "                g_output = self.G(noise)\n",
    "                label = torch.zeros(current_batch_size, device=self.device)\n",
    "                d_fake_output = self.D(g_output.detach()).flatten()\n",
    "                d_loss_fake = self.loss(d_fake_output, label)\n",
    "\n",
    "                d_loss = d_loss_real + d_loss_fake\n",
    "                d_loss.backward()\n",
    "\n",
    "                self.d_optimizer.step()\n",
    "\n",
    "                # Generator step\n",
    "                self.G.zero_grad()\n",
    "                label = torch.ones(current_batch_size, device=self.device)\n",
    "                d_fake_output = self.D(g_output).flatten()\n",
    "                g_loss = self.loss(d_fake_output, label)\n",
    "                g_loss.backward()\n",
    "                self.g_optimizer.step()\n",
    "\n",
    "                # Logging\n",
    "                d_loss_list.append(d_loss.item())\n",
    "                d_loss_real_list.append(d_loss_real.item())\n",
    "                d_loss_fake_list.append(d_loss_fake.item())\n",
    "                g_loss_list.append(g_loss.item())\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                images_count = 32\n",
    "                gen_images = self.generate(images_count)\n",
    "                plt.figure(figsize=(15, 15))\n",
    "                plt.axis(\"off\")\n",
    "                plt.title(\"Fake Images\")\n",
    "                plt.imshow(\n",
    "                    utils.make_grid(\n",
    "                        gen_images[:images_count].cpu(), padding=2, normalize=True\n",
    "                    ).permute(1, 2, 0)\n",
    "                )\n",
    "                plt.show()\n",
    "                self.G.train()\n",
    "                self.D.train()\n",
    "                path = (\n",
    "                    f\"/home/seara/Desktop/Github/vk-try/finalmodel{epoch}.pt\"\n",
    "                    if os.path.isdir(\"/home/seara/Desktop/Github/vk-try\")\n",
    "                    else f\"/content/drive/MyDrive/colab/finalmodel{epoch}.pt\"\n",
    "                )\n",
    "                self.save(path)\n",
    "\n",
    "            metrics = {\n",
    "                \"d_loss\": sum(d_loss_list) / len(d_loss_list),\n",
    "                \"d_loss_real\": sum(d_loss_real_list) / len(d_loss_real_list),\n",
    "                \"d_loss_fake\": sum(d_loss_fake_list) / len(d_loss_fake_list),\n",
    "                \"g_loss\": sum(g_loss_list) / len(g_loss_list),\n",
    "            }\n",
    "            print(f\"Epoch: {epoch}: {metrics}\")\n",
    "            wandb.log(metrics)\n",
    "\n",
    "    def generate(self, images_count):\n",
    "        self.D.eval()\n",
    "        self.G.eval()\n",
    "        with torch.no_grad():\n",
    "            noise = torch.randn(images_count, 100, 1, 1, device=self.device)\n",
    "            return self.G(noise)\n",
    "\n",
    "    def save(self, path):\n",
    "        save_dict = {\n",
    "            \"discriminator\": self.D.state_dict(),\n",
    "            \"generator\": self.G.state_dict(),\n",
    "            \"d_optimizer\": self.d_optimizer.state_dict(),\n",
    "            \"g_optimizer\": self.g_optimizer.state_dict(),\n",
    "        }\n",
    "        torch.save(save_dict, path)\n",
    "\n",
    "    def load(self, path):\n",
    "        load_dict = torch.load(path)\n",
    "\n",
    "        if \"generator\" in load_dict:\n",
    "            print(\"Loaded gen\")\n",
    "            self.G.load_state_dict(load_dict[\"generator\"])\n",
    "        if \"discriminator\" in load_dict:\n",
    "            print(\"Loaded dis\")\n",
    "            self.D.load_state_dict(load_dict[\"discriminator\"])\n",
    "        if \"d_optimizer\" in load_dict:\n",
    "            print(\"Loaded d_opt\")\n",
    "            self.d_optimizer.load_state_dict(load_dict[\"d_optimizer\"])\n",
    "        if \"g_optimizer\" in load_dict:\n",
    "            print(\"Loaded g_opt\")\n",
    "            self.g_optimizer.load_state_dict(load_dict[\"g_optimizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageFolder(\n",
    "    root=DATAROOT,\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(IMAGE_SIZE),\n",
    "            # transforms.ColorJitter(saturation=1, hue=0.5),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "dataloader = DataLoader(\n",
    "    dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=WORKERS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = next(iter(dataloader))[0][4]\n",
    "# plt.figure(figsize=(15, 15))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.axis(\"off\")\n",
    "# plt.title(\"Training Images\")\n",
    "# plt.imshow(image.permute(1, 2, 0))\n",
    "\n",
    "# jitter = transforms.ColorJitter(saturation=0.5, hue=0.5)\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.axis(\"off\")\n",
    "# plt.title(\"Training Images\")\n",
    "# plt.imshow(jitter(image).permute(1, 2, 0))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d(100, 1024, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU(inplace=True)\n",
      "  )\n",
      "  (output): Sequential(\n",
      "    (0): ConvTranspose2d(128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): Tanh()\n",
      "  )\n",
      ")\n",
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (output): Sequential(\n",
      "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = DCGAN(NUM_EPOCHS, LR, BETA1, DEVICE)\n",
    "model.train(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images_count = 32\n",
    "\n",
    "# plt.figure(figsize=(15, 15))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.axis(\"off\")\n",
    "# plt.title(\"Training Images\")\n",
    "# plt.imshow(\n",
    "#     utils.make_grid(\n",
    "#         next(iter(dataloader))[0][:images_count], padding=2, normalize=True\n",
    "#     ).permute(1, 2, 0)\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# image = next(iter(dataloader))[0]\n",
    "# plt.figure(figsize=(15, 15))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.axis(\"off\")\n",
    "# plt.title(\"Training Images\")\n",
    "# plt.imshow(image[0].permute(1, 2, 0))\n",
    "# # Plot the fake images from the last epoch\n",
    "# gen_images = model.generate(images_count)\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.axis(\"off\")\n",
    "# plt.title(\"Fake Images\")\n",
    "# plt.imshow(\n",
    "#     utils.make_grid(gen_images[:images_count].cpu(), padding=2, normalize=True).permute(\n",
    "#         1, 2, 0\n",
    "#     )\n",
    "# )\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"model800.pt\"\n",
    "# save = {\n",
    "#     \"discriminator\": model.D.state_dict(),\n",
    "#     \"generator\": model.G.state_dict(),\n",
    "#     \"d_optimizer\": model.d_optimizer.state_dict(),\n",
    "#     \"g_optimizer\": model.g_optimizer.state_dict(),\n",
    "# }\n",
    "# torch.save(save, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load = torch.load(path)\n",
    "# loaded_model = DCGAN(num_epochs=NUM_EPOCHS, lr=LR, beta1=BETA1, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_images = loaded_model.generate(images_count)\n",
    "# plt.figure(figsize=(15, 15))\n",
    "# plt.axis(\"off\")\n",
    "# plt.title(\"Fake Images\")\n",
    "# plt.imshow(\n",
    "#     utils.make_grid(gen_images[:images_count].cpu(), padding=2, normalize=True).permute(\n",
    "#         1, 2, 0\n",
    "#     )\n",
    "# )\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('DS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f71e6a37751bfa5febd38ff7ad3a4b7d5bb2a862907af32a1cce2c38073140c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
